[SETTINGS]
#images are asumed to be in this format
datatype = .tif

#CREATION OF LABELS from polygons in a geopackage
geopackage 		= example_dataset/labels/example_dataset_ground_surface.gpkg
attribute = ML_CATEGORY
#areas not covered by a polygon are considered to be unknown (ignore_id)
background_value = 0 
ignore_id = 0
#label folder
mask_folder 		= example_dataset/labels/large_label
splitted_mask_folder 		= example_dataset/labels/splitted_labels


#folder where the 'lod-images' should be stored. These images form the basis of our dataset before extra channels are added to them and some of them are removed becaus of lack of label data. We will create one label for each image in this set (if there are any label data for the area)
#image_folder 		= T:/trainingdata/befastelse/befaestelse_dataset_creation_test/data/large_lod_rgb_images

#SPLITTING UP THE DATA AND LABELS INTO PATHCES
#defining how large the pathces should be
tile_size_y = 1000
tile_size_x = 1000

#how many pixels should ther be of overlap between the patches?
overlap= 40

#All differetn kinds of images (lod images, DSM etc etc) are from the beginning located in the same folder
folder_containing_all_image_types = example_dataset/data/original_data

#the different kinds of images (cir == lod_cir  .tif == lod_rgb)
datatypes = ["DSM","DTM","OrtoCIR","OrtoRGB","cir","rgb"]

data_folder = example_dataset/data
splitted_data_parent_folder = example_dataset/data/splitted
images_that_define_areas_to_create_labels_for = example_dataset/data/OrtoRGB
#

#DEFINING TRAIN AND VALIDATION SETS
#used for creating the all.txt train.txt and valid.txt that defines what images we train and validate on. This folder is normally identicall to the one identified by 'splitted_image_folder' 
#path_to_images = T:/trainingdata/befastelse/befaestelse_dataset_creation_test_2/data/splitted_OrtoRGB
all_txt_filename = example_dataset/data/all.txt
#When using a fixed validation set the path that 'valid_txt_filename' points to must allready exist
use_fixed_validation_set = False
valid_txt_filename = example_dataset/data/valid.txt
train_txt_filename = example_dataset/data/train.txt

#if images overlap with thimages in validationset , they can not be allowed into the trainingset. We therfore remove them from all.txt
remove_images_from_all_that_overlap_with_validationset= False
remove_images_without_label = False


#when dividing the dataset into train and validation set we select every 5th image for the validation set
#on a larger dataset every 17 or higher might be more suitable
nr_of_images_between_validation_samples = 5
